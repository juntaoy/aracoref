# Word embeddings.
ft_ar_300d{
  path = ../fasttext/cc.ar.300.vec
  size = 300
}

# Main configuration.
arabic_bert {
  # Computation limits.
  max_top_antecedents = 50
  max_training_sentences = 50
  top_span_ratio = 0.4

  # Model hyperparameters.
  filter_widths = [3, 4, 5]
  filter_size = 50
  char_embedding_size = 8
  char_vocab_path = char_vocab.arabic.txt
  context_embeddings = ${ft_ar_300d}
  head_embeddings = ${ft_ar_300d}
  contextualization_size = 200
  contextualization_layers = 3
  ffnn_size = 150
  ffnn_depth = 2
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_features = true
  model_heads = true
  coref_depth = 2
  lm_layers = 4
  lm_size = 768
  coarse_to_fine = true

  # Learning hyperparameters.
  max_gradient_norm = 5.0
  lstm_dropout_rate = 0.4
  lexical_dropout_rate = 0.5
  dropout_rate = 0.2
  optimizer = adam
  learning_rate = 0.001
  decay_rate = 0.999
  decay_frequency = 100

  # Other.
  train_path = train.arabic.jsonlines
  eval_path = dev.arabic.jsonlines
  conll_eval_path = dev.arabic.v4_gold_conll
  lm_path = bert_arb_conll12_features.hdf5
  test_path = test.arabic.jsonlines
  conll_test_path = test.arabic.v4_gold_conll
  genres = ["bc", "bn", "mz", "nw", "pt", "tc", "wb"]
  eval_frequency = 500
  report_frequency = 100
  log_root = logs
  max_step = 400000
  use_joint_coref=true
  use_e2e_annealing=false
}

arabic_cleaned_bert = ${arabic_bert}{
  train_path = train.arabic.cleaned.pred.mentions.jsonlines
  eval_path = dev.arabic.cleaned.pred.mentions.jsonlines
  lm_path = bert_arb_conll12_cleaned_features.hdf5
  test_path = test.arabic.cleaned.pred.mentions.jsonlines
}


arabic_cleaned_arabert = ${arabic_cleaned_bert}{
  lm_path = arabert_arb_conll12_cleaned_features.hdf5
}


arabic_cleaned_arabert_e2e_annealing = ${arabic_cleaned_arabert}{
  use_e2e_annealing = true
}


